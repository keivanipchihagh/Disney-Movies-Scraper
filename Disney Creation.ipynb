{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "romantic-poison",
   "metadata": {},
   "source": [
    "# Disney Database Creation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-wellington",
   "metadata": {},
   "source": [
    "## Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "international-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import urllib\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-tucson",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-advocacy",
   "metadata": {},
   "source": [
    "### Task #1 - Get the info box\n",
    "Get the information on the info box and save it in the Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emotional-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_soup(soup):\n",
    "    ''' Cleans up the soup, removes some tags, refrences, ... '''\n",
    "    \n",
    "    for tag in soup.find_all(['span', 'sup']):\n",
    "        tag.decompose()\n",
    "        \n",
    "\n",
    "def clean_value(key, value):\n",
    "    ''' Cleans the value '''\n",
    "\n",
    "    if key != 'Release date':\n",
    "        value = re.sub(r'\\([^)]*\\)', '', value)\n",
    "        \n",
    "    return value.strip().replace('\\xa0', ' ').replace('\\n', ',')\n",
    "\n",
    "\n",
    "def get_movie_info(url):\n",
    "    ''' Scraps the movie information from Wikipedia '''\n",
    "    \n",
    "    # Get the webpage content\n",
    "    content = requests.get(url).content\n",
    "    \n",
    "    # Convert the content into BeautifulSoup object\n",
    "    soup = bs(content)\n",
    "    \n",
    "    # Cleans up the Beautiful soup\n",
    "    clean_soup(soup)\n",
    "    \n",
    "    # Search for the info box\n",
    "    info_box = soup.find(class_ = 'infobox vevent')\n",
    "    \n",
    "    # Get table rows\n",
    "    info_rows = info_box.find_all('tr')\n",
    "    \n",
    "    movie = {}    \n",
    "    for index, row in enumerate(info_rows):\n",
    "        \n",
    "        # Movie title\n",
    "        if index == 0: movie['title'] = row.find('th').get_text()\n",
    "        # Movie cover\n",
    "        elif index == 1:\n",
    "            movie['Cover Url'] = 'https:' + row.find('img')['src']\n",
    "        # Other movie properties\n",
    "        elif index != 1:\n",
    "            \n",
    "            # Get key\n",
    "            key = row.find('th').get_text(' ', strip = True)\n",
    "            \n",
    "            # Get raw value\n",
    "            raw_value = row.find('td').get_text()\n",
    "            \n",
    "            # Processed value\n",
    "            processed_value = clean_value(key, raw_value)\n",
    "            \n",
    "            # Add to the dictionary\n",
    "            movie[key] = processed_value\n",
    "\n",
    "    # Add movie URL\n",
    "    movie['url'] = url\n",
    "    \n",
    "    return movie\n",
    "\n",
    "\n",
    "# get_movie_info('https://en.wikipedia.org/wiki/Cinderella_(1950_film)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-committee",
   "metadata": {},
   "source": [
    "### Task #2 - Scape all info boxes on for Disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regular-apparel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping... (0 / 450)\n",
      "Scraping... (10 / 450)\n",
      "Scraping... (20 / 450)\n",
      "Scraping... (30 / 450)\n",
      "ERROR - Johnny Tremain - https://en.wikipedia.org//wiki/Johnny_Tremain_(film) - 'NoneType' object has no attribute 'find_all'\n",
      "Scraping... (40 / 450)\n",
      "ERROR - Zorro the Avenger - https://en.wikipedia.org//wiki/Zorro_(1957_TV_series)#Theatrical - 'NoneType' object has no attribute 'get_text'\n",
      "ERROR - The Sign of Zorro - https://en.wikipedia.org//wiki/Zorro_(1957_TV_series)#Theatrical - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (50 / 450)\n",
      "Scraping... (60 / 450)\n",
      "Scraping... (70 / 450)\n",
      "Scraping... (80 / 450)\n",
      "Scraping... (90 / 450)\n",
      "Scraping... (100 / 450)\n",
      "Scraping... (110 / 450)\n",
      "ERROR - One Little Indian - https://en.wikipedia.org//wiki/One_Little_Indian_(film) - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (120 / 450)\n",
      "ERROR - The Best of Walt Disney's True-Life Adventures - https://en.wikipedia.org//wiki/The_Best_of_Walt_Disney%27s_True-Life_Adventures - 'NoneType' object is not subscriptable\n",
      "ERROR - True-Life Adventures - https://en.wikipedia.org//wiki/True-Life_Adventures - 'NoneType' object has no attribute 'find_all'\n",
      "Scraping... (130 / 450)\n",
      "Scraping... (140 / 450)\n",
      "Scraping... (150 / 450)\n",
      "Scraping... (160 / 450)\n",
      "Scraping... (170 / 450)\n",
      "Scraping... (180 / 450)\n",
      "Scraping... (190 / 450)\n",
      "Scraping... (200 / 450)\n",
      "Scraping... (210 / 450)\n",
      "Scraping... (220 / 450)\n",
      "Scraping... (230 / 450)\n",
      "Scraping... (240 / 450)\n",
      "Scraping... (250 / 450)\n",
      "ERROR - Spirited Away - https://en.wikipedia.org//wiki/Spirited_Away - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (260 / 450)\n",
      "Scraping... (270 / 450)\n",
      "Scraping... (280 / 450)\n",
      "ERROR - Howl's Moving Castle - https://en.wikipedia.org//wiki/Howl%27s_Moving_Castle_(film) - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (290 / 450)\n",
      "Scraping... (300 / 450)\n",
      "ERROR - The Nightmare Before Christmas 3D - https://en.wikipedia.org//wiki/The_Nightmare_Before_Christmas - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (310 / 450)\n",
      "Scraping... (320 / 450)\n",
      "ERROR - The Secret of the Magic Gourd - https://en.wikipedia.org//wiki/The_Secret_of_the_Magic_Gourd_(2007_film) - 'NoneType' object is not subscriptable\n",
      "ERROR - Ponyo - https://en.wikipedia.org//wiki/Ponyo - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (330 / 450)\n",
      "Scraping... (340 / 450)\n",
      "ERROR - Tales from Earthsea - https://en.wikipedia.org//wiki/Tales_from_Earthsea_(film) - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (350 / 450)\n",
      "ERROR - The Secret World of Arrietty - https://en.wikipedia.org//wiki/Arrietty - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (360 / 450)\n",
      "Scraping... (370 / 450)\n",
      "ERROR - Khoobsurat - https://en.wikipedia.org//wiki/Khoobsurat_(2014_film) - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (380 / 450)\n",
      "Scraping... (390 / 450)\n",
      "ERROR - Tini: The Movie - https://en.wikipedia.org//wiki/Tini:_The_Movie - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (400 / 450)\n",
      "ERROR - Born in China - https://en.wikipedia.org//wiki/Born_in_China - 'NoneType' object has no attribute 'get_text'\n",
      "Scraping... (410 / 450)\n",
      "Scraping... (420 / 450)\n",
      "Scraping... (430 / 450)\n",
      "Scraping... (440 / 450)\n",
      "ERROR - Shrunk - https://en.wikipedia.org//wiki/Shrunk_(film) - 'NoneType' object is not subscriptable\n",
      "Done.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c6336d34787e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mmovie_info_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_disney_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0msave_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_info_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raw_disney_movies'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'save_data' is not defined"
     ]
    }
   ],
   "source": [
    "def get_disney_movies(url):\n",
    "    ''' Scrapes through all links on Disney Wikipedia page '''\n",
    "    \n",
    "    # Get the webpage content\n",
    "    content = requests.get(url).content\n",
    "    \n",
    "    # Convert the content into BeautifulSoup object\n",
    "    soup = bs(content)\n",
    "    \n",
    "    movies = soup.select('.wikitable.sortable i a')\n",
    "    \n",
    "    movie_info_list = []\n",
    "    for index, movie in enumerate(movies):\n",
    "        \n",
    "        if index % 10 == 0:\n",
    "            print('Scraping... ({0} / {1})'.format(index, len(movies)))\n",
    "\n",
    "        # Create movie URL and Title\n",
    "        movie_url = 'https://en.wikipedia.org/' + movie['href']\n",
    "        movie_title = movie.get_text()\n",
    "\n",
    "        try:\n",
    "            # Append movie info to the list\n",
    "            movie_info_list.append(get_movie_info(movie_url))\n",
    "\n",
    "        except Exception as ex:\n",
    "            # Print exception trace\n",
    "            print('ERROR', movie_title, movie_url, ex, sep = ' - ')\n",
    "\n",
    "    print('Done.')\n",
    "    return movie_info_list\n",
    "\n",
    "movie_info_list = get_disney_movies('https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films')\n",
    "# save_data(movie_info_list, name = 'raw_disney_movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-badge",
   "metadata": {},
   "source": [
    "#### Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-punch",
   "metadata": {},
   "source": [
    "##### As JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informal-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, name = 'raw_disney_movies'):\n",
    "    ''' Saves the data into .json format '''\n",
    "    \n",
    "    with open('datasets/' + name + '.json', 'w', encoding = 'utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-wireless",
   "metadata": {},
   "source": [
    "##### As Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graduate-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, name = 'cleaned_pickle_disney_movies'):\n",
    "    ''' Saves the data info pickle object '''\n",
    "    \n",
    "    with open('datasets/' + name + '.pickle', 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-sphere",
   "metadata": {},
   "source": [
    "##### As CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tough-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(data, name = 'csv_pickle_disney_movies'):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('datasets/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-reform",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-stockholm",
   "metadata": {},
   "source": [
    "##### As JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opening-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name = 'raw_disney_movies'):\n",
    "    ''' Reads the saved .json formatted file '''\n",
    "\n",
    "    with open('datasets/' + name + '.json', 'r', encoding = 'utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-singles",
   "metadata": {},
   "source": [
    "##### As Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "revised-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(name = 'cleaned_pickle_disney_movies'):\n",
    "    ''' Loads the data from a pickle object '''\n",
    "    \n",
    "    with open('datasets/' + name + '.pickle', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-latter",
   "metadata": {},
   "source": [
    "##### As CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shaped-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(name = 'csv_pickle_disney_movies'):\n",
    "    return pd.read_csv('datasets/' + name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-anxiety",
   "metadata": {},
   "source": [
    "### Task #3 - Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "composed-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(movie_info_list, name = 'raw_disney_movies')\n",
    "movie_info_list = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-tobago",
   "metadata": {},
   "source": [
    "#### Fix Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "moved-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minute_to_integer(running_time):\n",
    "    ''' Converts the running time to integer format '''\n",
    "\n",
    "    if isinstance(running_time, list):\n",
    "        return running_time[0].split(' ')[0]\n",
    "    else:\n",
    "        return running_time.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inner-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert running time to integer format\n",
    "\n",
    "for movie in movie_info_list:\n",
    "    movie['Running time'] = minute_to_integer(movie.get('Running time', 'N/A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-titanium",
   "metadata": {},
   "source": [
    "#### Fix Budgets and Box Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spatial-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def budget_to_integer(money):\n",
    "    ''' Converts budget into integer format '''\n",
    "    \n",
    "    if money == 'N/A': return money\n",
    "    \n",
    "    # Handle lists\n",
    "    if isinstance(money, list): money = money[0]\n",
    "    \n",
    "    # Mapper\n",
    "    mapper = {\n",
    "        'billion': 10 ** 9,\n",
    "        'million': 10 ** 6,\n",
    "        'thousand': 10 ** 3,\n",
    "        'default': 1,\n",
    "    }\n",
    "    \n",
    "    # Patterns\n",
    "    value_pattern = r'\\d+(,\\d{3})*\\.*\\d*'\n",
    "    quantity_pattern = r'thousand|million|billion'\n",
    "    \n",
    "    value_re = rf'\\$({value_pattern})'\n",
    "    quantity_re = rf'\\${value_pattern}-?{value_pattern}?\\s*({quantity_pattern})?'\n",
    "    \n",
    "    # Get the value and quantity\n",
    "    try: value = float(re.search(value_re, money).group(1).replace(',', ''))\n",
    "    except: return 'N/A'\n",
    "    \n",
    "    try:\n",
    "        quantity = re.search(quantity_re, money).group(3)\n",
    "        \n",
    "        # Raise exception if quantity is not found\n",
    "        if quantity is None: raise Exception()\n",
    "    except: quantity = 'default'\n",
    "    \n",
    "    return str(value * mapper[quantity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "placed-confidentiality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_null(value):\n",
    "    ''' Returns N/A if value is not set '''\n",
    "    return 'N/A' if value in ['', 'unknown'] else value\n",
    "\n",
    "\n",
    "for index, movie in enumerate(movie_info_list):\n",
    "    \n",
    "    box_office = clean_null(movie.get('Box office', 'N/A'))\n",
    "    budget = clean_null(movie.get('Budget', 'N/A'))\n",
    "    \n",
    "    if box_office == '': box_office = 'N/A'\n",
    "    if budget == '': budget = 'N/A'\n",
    "    \n",
    "    movie['Box office'] = budget_to_integer(box_office)\n",
    "    movie['Budget'] = budget_to_integer(budget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-rings",
   "metadata": {},
   "source": [
    "### Task #4 - Convert dates into date object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worth-railway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_date(date, pattern = r'([A-Za-z]+)\\s(\\d+),\\s(\\d+)'):\n",
    "    ''' Extracts the date from the string '''\n",
    "    \n",
    "    # Error handling\n",
    "    if date == 'N/A': return date\n",
    "    return re.search(pattern, date).groups()\n",
    "\n",
    "\n",
    "def create_date(date_str):\n",
    "    ''' Creates a date object '''\n",
    "\n",
    "    return datetime.strptime(date_str, '%B %d %Y')\n",
    "\n",
    "\n",
    "for index, movie in enumerate(movie_info_list):\n",
    "\n",
    "    # Try with the default pattern\n",
    "    try:\n",
    "        date = get_date(movie.get('Release date', 'N/A'))\n",
    "    except:\n",
    "        # Try with alternative pattern\n",
    "        try:\n",
    "            date = get_date(movie.get('Release date', 'N/A'), pattern = r'^(\\d+)\\s([A-Za-z]+)\\s(\\d+)')\n",
    "            date = (date[1], date[0], date[2])\n",
    "        except: continue\n",
    "    \n",
    "    if date != 'N/A':\n",
    "        date = create_date(' '.join(date))\n",
    "#     print(date)\n",
    "    \n",
    "    movie['Release date'] = date\n",
    "    \n",
    "# Save as Pickle (Not JSON!!!)\n",
    "save_pickle(movie_info_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-warrior",
   "metadata": {},
   "source": [
    "### Attach IMDB/Rotten Tomatoes/Metascore Scores and other Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "urban-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info_list = load_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "established-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "OMDB_API_base_url = 'http://www.omdbapi.com/?'\n",
    "\n",
    "def get_OMDB_movie_info(title):\n",
    "    ''' Uses the API to capture movie information '''\n",
    "    \n",
    "    # Parameters\n",
    "    parameters = { 'apikey': '82c41530', 't': title}\n",
    "    encoded_parameters = urllib.parse.urlencode(parameters)\n",
    "\n",
    "    # Return request results\n",
    "    return requests.get(OMDB_API_base_url + encoded_parameters).json()\n",
    "\n",
    "\n",
    "def get_rotten_tomatoes_score(omdb_info):\n",
    "    \n",
    "    ratings = omdb_info.get('Ratings', [])\n",
    "    \n",
    "    for rating in ratings:\n",
    "        if rating['Source'] == 'Rotten Tomatoes':\n",
    "            return rating['Value']\n",
    "    \n",
    "    # Just in case no score is present\n",
    "    return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alike-course",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting API info... (0/433)\n",
      "Getting API info... (10/433)\n",
      "Getting API info... (20/433)\n",
      "Getting API info... (30/433)\n",
      "Getting API info... (40/433)\n",
      "Getting API info... (50/433)\n",
      "Getting API info... (60/433)\n",
      "Getting API info... (70/433)\n",
      "Getting API info... (80/433)\n",
      "Getting API info... (90/433)\n",
      "Getting API info... (100/433)\n",
      "Getting API info... (110/433)\n",
      "Getting API info... (120/433)\n",
      "Getting API info... (130/433)\n",
      "Getting API info... (140/433)\n",
      "Getting API info... (150/433)\n",
      "Getting API info... (160/433)\n",
      "Getting API info... (170/433)\n",
      "Getting API info... (180/433)\n",
      "Getting API info... (190/433)\n",
      "Getting API info... (200/433)\n",
      "Getting API info... (210/433)\n",
      "Getting API info... (220/433)\n",
      "Getting API info... (230/433)\n",
      "Getting API info... (240/433)\n",
      "Getting API info... (250/433)\n",
      "Getting API info... (260/433)\n",
      "Getting API info... (270/433)\n",
      "Getting API info... (280/433)\n",
      "Getting API info... (290/433)\n",
      "Getting API info... (300/433)\n",
      "Getting API info... (310/433)\n",
      "Getting API info... (320/433)\n",
      "Getting API info... (330/433)\n",
      "Getting API info... (340/433)\n",
      "Getting API info... (350/433)\n",
      "Getting API info... (360/433)\n",
      "Getting API info... (370/433)\n",
      "Getting API info... (380/433)\n",
      "Getting API info... (390/433)\n",
      "Getting API info... (400/433)\n",
      "Error on 402\n",
      "Getting API info... (410/433)\n",
      "Getting API info... (420/433)\n",
      "Getting API info... (430/433)\n"
     ]
    }
   ],
   "source": [
    "for index, movie in enumerate(movie_info_list):\n",
    "    \n",
    "    if index % 10 == 0:\n",
    "        print('Getting API info... ({0}/{1})'.format(index, len(movie_info_list)))\n",
    "        \n",
    "    try:\n",
    "        # Get OMDB info by title\n",
    "        omdb_info = get_OMDB_movie_info(movie['title'])\n",
    "    \n",
    "        # Get scores\n",
    "        movie['Rotten Tomatoes'] = get_rotten_tomatoes_score(omdb_info)\n",
    "        movie['IMDB'] = omdb_info.get('imdbRating', 'N/A')    \n",
    "        movie['Metascore'] = omdb_info.get('Metascore', 'N/A')\n",
    "\n",
    "        # Other info\n",
    "        movie['Rated'] = omdb_info.get('Rated', 'N/A')\n",
    "        movie['Language'] = omdb_info.get('Language', 'N/A')\n",
    "        movie['Awards'] = omdb_info.get('Awards', 'N/A')\n",
    "        movie['Poster'] = omdb_info.get('Poster', 'N/A')\n",
    "        movie['Genre'] = omdb_info.get('Genre', 'N/A')\n",
    "        movie['Plot'] = omdb_info.get('Plot', 'N/A')    \n",
    "    except:\n",
    "        print('Error on {0}'.format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binary-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(movie_info_list)\n",
    "# movie_info_list = load_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
